# Colab-ready ADDA (MNIST -> USPS) with t-SNE visualization of latent features
# Requirements: PyTorch, torchvision, scikit-learn, matplotlib
# Run on GPU runtime in Colab

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
from torchvision.datasets import MNIST, USPS
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
from tqdm import tqdm

# ----------------------
# Config
# ----------------------
SEED = 42
BATCH_SIZE = 128
LR = 1e-3
SRC_EPOCHS = 20         # Increase for stronger source
ADDA_EPOCHS = 50        # Increase for better adaptation
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
PRINT_EVERY = 100

# Fix seeds
def set_seed(seed=SEED):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
set_seed()

# ----------------------
# Data: MNIST -> USPS
# ----------------------
# USPS images are 16x16 grayscale; resize to 28x28 to match MNIST
mnist_transform = transforms.Compose([
    transforms.Resize((28,28)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
usps_transform = transforms.Compose([
    transforms.Resize((28,28)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# Download datasets
train_mnist = MNIST(root="./data", train=True, download=True, transform=mnist_transform)
test_mnist = MNIST(root="./data", train=False, download=True, transform=mnist_transform)
train_usps = USPS(root="./data", train=True, download=True, transform=usps_transform)
test_usps = USPS(root="./data", train=False, download=True, transform=usps_transform)

src_loader = DataLoader(train_mnist, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
src_test_loader = DataLoader(test_mnist, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
tgt_loader = DataLoader(train_usps, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)
tgt_test_loader = DataLoader(test_usps, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

# ----------------------
# Models: Encoder, Classifier, Discriminator
# ----------------------
class Encoder(nn.Module):
    def __init__(self):
        super().__init__()
        # Simple conv net to produce latent feature vector
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 5, stride=1, padding=2), #28x28 -> 28x28
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2), #14x14
            nn.Conv2d(32, 48, 5, stride=1, padding=2),
            nn.BatchNorm2d(48),
            nn.ReLU(),
            nn.MaxPool2d(2), #7x7
        )
        self.flatten = nn.Flatten()
        self.fc = nn.Sequential(
            nn.Linear(48*7*7, 256),
            nn.ReLU(),
        )
    def forward(self, x):
        x = self.features(x)
        x = self.flatten(x)
        x = self.fc(x)
        return x  # latent vector (256-d)

class Classifier(nn.Module):
    def __init__(self, n_classes=10):
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(256, 100),
            nn.ReLU(),
            nn.Linear(100, n_classes)
        )
    def forward(self, x):
        return self.classifier(x)

class Discriminator(nn.Module):
    def __init__(self):
        super().__init__()
        # binary domain discriminator: source vs target (output single logit)
        self.net = nn.Sequential(
            nn.Linear(256, 500),
            nn.ReLU(),
            nn.Linear(500, 500),
            nn.ReLU(),
            nn.Linear(500, 2)  # logits for domain
        )
    def forward(self, x):
        return self.net(x)

# Instantiate
src_encoder = Encoder().to(DEVICE)
tgt_encoder = Encoder().to(DEVICE)
classifier = Classifier().to(DEVICE)
discriminator = Discriminator().to(DEVICE)

# ----------------------
# Utilities
# ----------------------
def train_source(src_encoder, classifier, dataloader, epochs=SRC_EPOCHS, lr=LR):
    src_encoder.train(); classifier.train()
    criterion = nn.CrossEntropyLoss()
    params = list(src_encoder.parameters()) + list(classifier.parameters())
    opt = optim.Adam(params, lr=lr)
    for epoch in range(epochs):
        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f"Source Pretrain Epoch {epoch+1}/{epochs}")
        for i, (x, y) in pbar:
            x,y = x.to(DEVICE), y.to(DEVICE)
            opt.zero_grad()
            feat = src_encoder(x)
            logits = classifier(feat)
            loss = criterion(logits, y)
            loss.backward()
            opt.step()
            if (i+1) % PRINT_EVERY == 0:
                acc = (logits.argmax(1)==y).float().mean().item()
                pbar.set_postfix(loss=loss.item(), acc=acc)
    return src_encoder, classifier

def eval_classifier(encoder, classifier, dataloader):
    encoder.eval(); classifier.eval()
    correct=0; total=0
    with torch.no_grad():
        for x,y in dataloader:
            x,y = x.to(DEVICE), y.to(DEVICE)
            feat = encoder(x)
            logits = classifier(feat)
            pred = logits.argmax(1)
            correct += (pred==y).sum().item()
            total += y.size(0)
    return correct/total

# ----------------------
# Step 1: Pretrain source encoder + classifier on MNIST
# ----------------------
print("Pretraining source model on MNIST...")
src_encoder, classifier = train_source(src_encoder, classifier, src_loader, epochs=SRC_EPOCHS)
src_acc = eval_classifier(src_encoder, classifier, src_test_loader)
print(f"Source test accuracy on MNIST: {src_acc*100:.2f}%")

# Initialize target encoder weights.
# ADDA paper suggests initializing target encoder with source encoder weights (then adversarially adapt).
tgt_encoder.load_state_dict(src_encoder.state_dict())  # initialize

# Evaluate classifier directly on USPS (without adaptation) using target encoder (which is same as source encoder)
init_tgt_acc = eval_classifier(tgt_encoder, classifier, tgt_test_loader)
print(f"Initial target (USPS) accuracy using source encoder (no adaptation): {init_tgt_acc*100:.2f}%")

# ----------------------
# Feature extraction function
# ----------------------
def extract_features(encoder, dataloader, max_samples=None):
    encoder.eval()
    feats = []
    labels = []
    with torch.no_grad():
        for x,y in dataloader:
            x = x.to(DEVICE)
            f = encoder(x).cpu().numpy()
            feats.append(f)
            labels.append(y.numpy())
            if max_samples is not None:
                cur = sum([a.shape[0] for a in feats])
                if cur >= max_samples:
                    break
    feats = np.concatenate(feats, axis=0)
    labels = np.concatenate(labels, axis=0)
    if max_samples is not None:
        feats = feats[:max_samples]
        labels = labels[:max_samples]
    return feats, labels

# Extract initial features for USPS (Init USPS)
print("Extracting initial USPS latent features (pre-adaptation)...")
init_feats, init_labels = extract_features(tgt_encoder, tgt_test_loader, max_samples=2000)

# ----------------------
# ADDA: Train discriminator and target encoder adversarially
# ----------------------
# Losses and optimizers
bce = nn.CrossEntropyLoss()  # use CE on domain labels 0: source, 1: target
opt_dis = optim.Adam(discriminator.parameters(), lr=1e-4)
opt_tgt = optim.Adam(tgt_encoder.parameters(), lr=1e-4)

# Create source feature loader (features from source encoder)
def get_feature_loader(encoder, dataloader):
    # Return pairs of (feat, domain_label) where domain_label 0=source
    feats = []
    labs = []
    with torch.no_grad():
        for x,y in dataloader:
            x = x.to(DEVICE)
            f = encoder(x).cpu()
            feats.append(f)
            labs.append(torch.zeros(f.size(0), dtype=torch.long))
    feats = torch.cat(feats, dim=0)
    labs = torch.cat(labs, dim=0)
    dataset = torch.utils.data.TensorDataset(feats, labs)
    return DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)

# We'll repeatedly sample features from source encoder (frozen) and from target encoder (trainable) using raw images.
# Freeze source encoder
src_encoder.eval()
for p in src_encoder.parameters():
    p.requires_grad = False

print("Starting ADDA adaptation...")
for epoch in range(ADDA_EPOCHS):
    discriminator.train()
    tgt_encoder.train()
    pbar = tqdm(zip(iter(src_loader), iter(tgt_loader)),
                total=min(len(src_loader), len(tgt_loader)),
                desc=f"ADDA Epoch {epoch+1}/{ADDA_EPOCHS}")
    for (xs, ys), (xt, yt) in pbar:
        xs = xs.to(DEVICE)
        xt = xt.to(DEVICE)

        # 1) Train discriminator: classify source vs target features
        with torch.no_grad():
            fs = src_encoder(xs)  # source features (fixed)
        ft = tgt_encoder(xt).detach()  # target features, detach for discriminator step
        feats = torch.cat([fs, ft], dim=0)
        domain_labels = torch.cat([torch.zeros(fs.size(0), dtype=torch.long, device=DEVICE),
                                   torch.ones(ft.size(0), dtype=torch.long, device=DEVICE)], dim=0)

        opt_dis.zero_grad()
        preds = discriminator(feats)
        loss_dis = bce(preds, domain_labels)
        loss_dis.backward()
        opt_dis.step()

        # 2) Train target encoder to fool discriminator (labels = source(0) for target features)
        opt_tgt.zero_grad()
        ft2 = tgt_encoder(xt)
        preds_t = discriminator(ft2)
        # Want discriminator to predict 'source' (0) for target features -> encourage confusion
        fool_labels = torch.zeros(preds_t.size(0), dtype=torch.long, device=DEVICE)
        loss_tgt = bce(preds_t, fool_labels)
        loss_tgt.backward()
        opt_tgt.step()

        if random.random() < 0.005:
            pbar.set_postfix(loss_dis=loss_dis.item(), loss_tgt=loss_tgt.item())

    # optional: evaluate target classifier accuracy after every epoch
    tgt_acc = eval_classifier(tgt_encoder, classifier, tgt_test_loader)
    print(f"After ADDA epoch {epoch+1}, target test accuracy (classifier on adapted features): {tgt_acc*100:.2f}%")

# ----------------------
# Extract adapted features for USPS (ADDA USPS)
# ----------------------
print("Extracting adapted USPS latent features (post-adaptation)...")
adda_feats, adda_labels = extract_features(tgt_encoder, tgt_test_loader, max_samples=2000)

# ----------------------
# t-SNE visualization
# ----------------------
print("Running t-SNE (this may take a minute)...")
def plot_two_tsne(feats1, labels1, feats2, labels2, title1="Init USPS", title2="ADDA USPS", sample=1000):
    # align sample size
    n = min(len(feats1), len(feats2), sample)
    # sample randomly
    idx1 = np.random.choice(len(feats1), n, replace=False)
    idx2 = np.random.choice(len(feats2), n, replace=False)
    X = np.vstack([feats1[idx1], feats2[idx2]])
    tsne = TSNE(n_components=2, random_state=SEED, init='pca', perplexity=30)
    X2 = tsne.fit_transform(X)
    X1_2 = X2[:n]
    X2_2 = X2[n:]

    # plotting
    fig, axs = plt.subplots(1,2, figsize=(14,6))
    scatter1 = axs[0].scatter(X1_2[:,0], X1_2[:,1], c=labels1[idx1], cmap='tab10', s=8)
    axs[0].set_title(title1)
    axs[0].axis('off')
    scatter2 = axs[1].scatter(X2_2[:,0], X2_2[:,1], c=labels2[idx2], cmap='tab10', s=8)
    axs[1].set_title(title2)
    axs[1].axis('off')
    # legend
    handles = scatter1.legend_elements()[0]
    labels = [str(i) for i in range(10)]
    fig.legend(handles, labels, loc='lower center', ncol=10)
    plt.show()

plot_two_tsne(init_feats, init_labels, adda_feats, adda_labels, sample=1500)

# ----------------------
# Save adapters/models if desired
# ----------------------
OUT_DIR = "./models_adda"
os.makedirs(OUT_DIR, exist_ok=True)
torch.save(src_encoder.state_dict(), os.path.join(OUT_DIR, "src_encoder.pth"))
torch.save(tgt_encoder.state_dict(), os.path.join(OUT_DIR, "tgt_encoder_adapted.pth"))
torch.save(classifier.state_dict(), os.path.join(OUT_DIR, "classifier.pth"))
print(f"Saved models to {OUT_DIR}")

print("Done.")
